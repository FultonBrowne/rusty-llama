{
  "models": ["llama2", "llama-uncensored"],
  "port": 8000,
  "use_gpu": true
}